{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nclass InfinitySpark(nn.Module):\n    def __init__(self, num_classes):\n        super(InfinitySpark, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(512)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(512 * 14 * 14, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n        x = x.view(x.size(0), -1)\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.fc3(x)\n        return x\n\n\nnum_classes = 10\nmodel = InfinitySpark(num_classes)\n#model.load_state_dict(torch.load('/kaggle/working/custom.pth'))\n\nn_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:19.734634Z","iopub.execute_input":"2024-06-04T14:54:19.734988Z","iopub.status.idle":"2024-06-04T14:54:20.774446Z","shell.execute_reply.started":"2024-06-04T14:54:19.734961Z","shell.execute_reply":"2024-06-04T14:54:20.773505Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of Params: 104.8M\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'custom.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:21.903122Z","iopub.execute_input":"2024-06-04T14:54:21.903712Z","iopub.status.idle":"2024-06-04T14:54:22.682500Z","shell.execute_reply.started":"2024-06-04T14:54:21.903677Z","shell.execute_reply":"2024-06-04T14:54:22.681230Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef custom_tensorflow(num_classes):\n    inputs = tf.keras.Input(shape=(224, 224, 3))\n    \n    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)  # Layer 1\n    x = layers.BatchNormalization()(x)  # Layer 2\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 3\n    \n    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)  # Layer 4\n    x = layers.BatchNormalization()(x)  # Layer 5\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 6\n    \n    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)  # Layer 7\n    x = layers.BatchNormalization()(x)  # Layer 8\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 9\n    \n    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)  # Layer 10\n    x = layers.BatchNormalization()(x)  # Layer 11\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 12\n    \n    x = layers.Flatten()(x)  # Layer 13\n    x = layers.Dropout(0.5)(x)  # Layer 14\n    x = layers.Dense(1024, activation='relu')(x)  # Layer 15\n    x = layers.Dropout(0.5)(x) #16\n    x = layers.Dense(512, activation='relu')(x) #17\n    x = layers.Dropout(0.5)(x)  # Layer 18\n    outputs = layers.Dense(num_classes, activation='softmax')(x)  # Layer 19\n    \n    model = models.Model(inputs, outputs)\n    return model\n\n# Create an instance of the model\nnum_classes = 10\ntf_model = custom_tensorflow(num_classes)\n\nn_parameters = tf_model.count_params()\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:22.684695Z","iopub.execute_input":"2024-06-04T14:54:22.685014Z","iopub.status.idle":"2024-06-04T14:54:22.797408Z","shell.execute_reply.started":"2024-06-04T14:54:22.684988Z","shell.execute_reply":"2024-06-04T14:54:22.796509Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Number of Params: 104.8M\n","output_type":"stream"}]},{"cell_type":"code","source":"pytorch_model = InfinitySpark(num_classes)\n\npytorch_model.load_state_dict(torch.load('/kaggle/working/custom.pth', map_location=torch.device('cpu')))\npytorch_model.eval()\n\n# Helper function to convert PyTorch tensors to NumPy arrays\ndef pt_to_np(tensor):\n    return tensor.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:22.798369Z","iopub.execute_input":"2024-06-04T14:54:22.798625Z","iopub.status.idle":"2024-06-04T14:54:24.129983Z","shell.execute_reply.started":"2024-06-04T14:54:22.798603Z","shell.execute_reply":"2024-06-04T14:54:24.129014Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Map PyTorch weights to TensorFlow model\ntf_model.layers[1].set_weights([pt_to_np(pytorch_model.conv1.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv1.bias)])\ntf_model.layers[2].set_weights([pt_to_np(pytorch_model.bn1.weight), pt_to_np(pytorch_model.bn1.bias),\n                                pt_to_np(pytorch_model.bn1.running_mean), pt_to_np(pytorch_model.bn1.running_var)])\n\ntf_model.layers[4].set_weights([pt_to_np(pytorch_model.conv2.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv2.bias)])\ntf_model.layers[5].set_weights([pt_to_np(pytorch_model.bn2.weight), pt_to_np(pytorch_model.bn2.bias),\n                                pt_to_np(pytorch_model.bn2.running_mean), pt_to_np(pytorch_model.bn2.running_var)])\n\ntf_model.layers[7].set_weights([pt_to_np(pytorch_model.conv3.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv3.bias)])\ntf_model.layers[8].set_weights([pt_to_np(pytorch_model.bn3.weight), pt_to_np(pytorch_model.bn3.bias),\n                                pt_to_np(pytorch_model.bn3.running_mean), pt_to_np(pytorch_model.bn3.running_var)])\n\ntf_model.layers[10].set_weights([pt_to_np(pytorch_model.conv4.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv4.bias)])\ntf_model.layers[11].set_weights([pt_to_np(pytorch_model.bn4.weight), pt_to_np(pytorch_model.bn4.bias),\n                                 pt_to_np(pytorch_model.bn4.running_mean), pt_to_np(pytorch_model.bn4.running_var)])\n\ntf_model.layers[15].set_weights([pt_to_np(pytorch_model.fc1.weight.T), pt_to_np(pytorch_model.fc1.bias)])\ntf_model.layers[17].set_weights([pt_to_np(pytorch_model.fc2.weight.T), pt_to_np(pytorch_model.fc2.bias)])\ntf_model.layers[19].set_weights([pt_to_np(pytorch_model.fc3.weight.T), pt_to_np(pytorch_model.fc3.bias)])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:24.131306Z","iopub.execute_input":"2024-06-04T14:54:24.131660Z","iopub.status.idle":"2024-06-04T14:54:25.175819Z","shell.execute_reply.started":"2024-06-04T14:54:24.131627Z","shell.execute_reply":"2024-06-04T14:54:25.174999Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tf_model.save('custom.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:25.178443Z","iopub.execute_input":"2024-06-04T14:54:25.179001Z","iopub.status.idle":"2024-06-04T14:54:26.314178Z","shell.execute_reply.started":"2024-06-04T14:54:25.178964Z","shell.execute_reply":"2024-06-04T14:54:26.313028Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"load_tf_model = models.load_model('/kaggle/working/custom.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:26.315985Z","iopub.execute_input":"2024-06-04T14:54:26.316373Z","iopub.status.idle":"2024-06-04T14:54:27.259713Z","shell.execute_reply.started":"2024-06-04T14:54:26.316336Z","shell.execute_reply":"2024-06-04T14:54:27.258883Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"n_parameters = load_tf_model.count_params()\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:27.260838Z","iopub.execute_input":"2024-06-04T14:54:27.261198Z","iopub.status.idle":"2024-06-04T14:54:27.266261Z","shell.execute_reply.started":"2024-06-04T14:54:27.261167Z","shell.execute_reply":"2024-06-04T14:54:27.265326Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Number of Params: 104.8M\n","output_type":"stream"}]}]}