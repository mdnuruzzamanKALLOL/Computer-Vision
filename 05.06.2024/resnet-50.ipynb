{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = torch.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = torch.relu(out)\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=1000):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3, 4, 6, 3])\n\n# Create PyTorch model and load state\nmodel = ResNet50()\n\nn_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:36.806938Z","iopub.execute_input":"2024-06-05T14:07:36.807862Z","iopub.status.idle":"2024-06-05T14:07:37.096326Z","shell.execute_reply.started":"2024-06-05T14:07:36.807823Z","shell.execute_reply":"2024-06-05T14:07:37.095387Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of Params: 25.6M\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet50.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:37.722585Z","iopub.execute_input":"2024-06-05T14:07:37.722944Z","iopub.status.idle":"2024-06-05T14:07:37.940706Z","shell.execute_reply.started":"2024-06-05T14:07:37.722917Z","shell.execute_reply":"2024-06-05T14:07:37.939528Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef identity_block(input_tensor, kernel_size, filters, stage, block):\n    filters1, filters2, filters3 = filters\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a', use_bias=False)(input_tensor)\n    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b', use_bias=False)(x)\n    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n\n    x = layers.add([x, input_tensor])\n    x = layers.ReLU()(x)\n    return x\n\ndef conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    filters1, filters2, filters3 = filters\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a', use_bias=False)(input_tensor)\n    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b', use_bias=False)(x)\n    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n\n    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1', use_bias=False)(input_tensor)\n    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = layers.ReLU()(x)\n    return x\n\ndef ResNet50_tf(input_shape=(224, 224, 3), num_classes=1000):\n    img_input = layers.Input(shape=input_shape)\n    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n    x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n    x = layers.BatchNormalization(name='bn_conv1')(x)\n    x = layers.ReLU()(x)\n    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n    x = layers.Dense(num_classes, activation='softmax', name='fc1000')(x)\n\n    model = models.Model(img_input, x, name='resnet50')\n    return model\n\n# Create a TensorFlow ResNet-50 model\ntf_model = ResNet50_tf()\n\nn_parameters = tf_model.count_params()\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:37.944043Z","iopub.execute_input":"2024-06-05T14:07:37.944410Z","iopub.status.idle":"2024-06-05T14:07:43.108254Z","shell.execute_reply.started":"2024-06-05T14:07:37.944372Z","shell.execute_reply":"2024-06-05T14:07:43.107254Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-05 14:07:38.413941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-05 14:07:38.414001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-05 14:07:38.415403: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Number of Params: 25.6M\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print TensorFlow model layers to get their order\n# for i, layer in enumerate(tf_model.layers):\n#     print(i, layer.name, [w.shape for w in layer.get_weights()])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:43.109568Z","iopub.execute_input":"2024-06-05T14:07:43.110125Z","iopub.status.idle":"2024-06-05T14:07:43.114417Z","shell.execute_reply.started":"2024-06-05T14:07:43.110097Z","shell.execute_reply":"2024-06-05T14:07:43.113481Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"pytorch_model = ResNet50()\n\npytorch_model.load_state_dict(torch.load('/kaggle/working/resnet50.pth'))\npytorch_model.eval()\n\n# Helper function to convert PyTorch tensors to NumPy arrays\ndef pt_to_np(tensor):\n    return tensor.detach().cpu().numpy()\n\n# OR Try It\n# def pt_to_np(tensor):\n#     if tensor is None:\n#         return None\n#     return tensor.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:43.116306Z","iopub.execute_input":"2024-06-05T14:07:43.116586Z","iopub.status.idle":"2024-06-05T14:07:43.647821Z","shell.execute_reply.started":"2024-06-05T14:07:43.116562Z","shell.execute_reply":"2024-06-05T14:07:43.646903Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Map PyTorch weights to TensorFlow model\n# Initial convolution and batch normalization layers\ntf_model.layers[2].set_weights([pt_to_np(pytorch_model.conv1.weight.permute(2, 3, 1, 0))])\ntf_model.layers[3].set_weights([pt_to_np(pytorch_model.bn1.weight), pt_to_np(pytorch_model.bn1.bias),\n                                pt_to_np(pytorch_model.bn1.running_mean), pt_to_np(pytorch_model.bn1.running_var)])\n\n# Function to map the weights of a block\ndef map_block(layer_indices, block, block_name):\n    for i, layer_index in enumerate(layer_indices):\n        layer = tf_model.layers[layer_index]\n        if isinstance(layer, layers.Conv2D):\n            conv_weight = block[i].weight.permute(2, 3, 1, 0)\n            if block[i].bias is not None:\n                conv_bias = block[i].bias\n                layer.set_weights([pt_to_np(conv_weight), pt_to_np(conv_bias)])\n            else:\n                layer.set_weights([pt_to_np(conv_weight)])\n        elif isinstance(layer, layers.BatchNormalization):\n            bn_weight = block[i].weight\n            bn_bias = block[i].bias\n            bn_running_mean = block[i].running_mean\n            bn_running_var = block[i].running_var\n            layer.set_weights([pt_to_np(bn_weight), pt_to_np(bn_bias), pt_to_np(bn_running_mean), pt_to_np(bn_running_var)])\n\n# Define the block indices\nblock_indices = {\n    \"conv2_block1\": [7, 8, 10, 11, 13, 15],\n    \"conv2_block2\": [19, 20, 22, 23, 25, 27],\n    \"conv2_block3\": [29, 30, 32, 33, 35, 37],\n    \"conv3_block1\": [39, 40, 42, 43, 45, 47],\n    \"conv3_block2\": [51, 52, 54, 55, 57, 59],\n    \"conv3_block3\": [61, 62, 64, 65, 67, 69],\n    \"conv3_block4\": [71, 72, 74, 75, 77, 79],\n    \"conv4_block1\": [81, 82, 84, 85, 87, 89],\n    \"conv4_block2\": [93, 94, 96, 97, 99, 101],\n    \"conv4_block3\": [103, 104, 106, 107, 109, 111],\n    \"conv4_block4\": [113, 114, 116, 117, 119, 121],\n    \"conv4_block5\": [123, 124, 126, 127, 129, 131],\n    \"conv4_block6\": [133, 134, 136, 137, 139, 141],\n    \"conv5_block1\": [143, 144, 146, 147, 149, 151],\n    \"conv5_block2\": [155, 156, 158, 159, 161, 163],\n    \"conv5_block3\": [165, 166, 168, 169, 171, 173]\n}\n\n# Mapping each block\nmap_block(block_indices[\"conv2_block1\"], list(pytorch_model.layer1[0].children()), \"conv2_block1\")\nmap_block(block_indices[\"conv2_block2\"], list(pytorch_model.layer1[1].children()), \"conv2_block2\")\nmap_block(block_indices[\"conv2_block3\"], list(pytorch_model.layer1[2].children()), \"conv2_block3\")\nmap_block(block_indices[\"conv3_block1\"], list(pytorch_model.layer2[0].children()), \"conv3_block1\")\nmap_block(block_indices[\"conv3_block2\"], list(pytorch_model.layer2[1].children()), \"conv3_block2\")\nmap_block(block_indices[\"conv3_block3\"], list(pytorch_model.layer2[2].children()), \"conv3_block3\")\nmap_block(block_indices[\"conv3_block4\"], list(pytorch_model.layer2[3].children()), \"conv3_block4\")\nmap_block(block_indices[\"conv4_block1\"], list(pytorch_model.layer3[0].children()), \"conv4_block1\")\nmap_block(block_indices[\"conv4_block2\"], list(pytorch_model.layer3[1].children()), \"conv4_block2\")\nmap_block(block_indices[\"conv4_block3\"], list(pytorch_model.layer3[2].children()), \"conv4_block3\")\nmap_block(block_indices[\"conv4_block4\"], list(pytorch_model.layer3[3].children()), \"conv4_block4\")\nmap_block(block_indices[\"conv4_block5\"], list(pytorch_model.layer3[4].children()), \"conv4_block5\")\nmap_block(block_indices[\"conv4_block6\"], list(pytorch_model.layer3[5].children()), \"conv4_block6\")\nmap_block(block_indices[\"conv5_block1\"], list(pytorch_model.layer4[0].children()), \"conv5_block1\")\nmap_block(block_indices[\"conv5_block2\"], list(pytorch_model.layer4[1].children()), \"conv5_block2\")\nmap_block(block_indices[\"conv5_block3\"], list(pytorch_model.layer4[2].children()), \"conv5_block3\")\n# Fully connected layer\ntf_model.layers[176].set_weights([pt_to_np(pytorch_model.fc.weight.T), pt_to_np(pytorch_model.fc.bias)])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:43.649238Z","iopub.execute_input":"2024-06-05T14:07:43.649840Z","iopub.status.idle":"2024-06-05T14:07:43.912847Z","shell.execute_reply.started":"2024-06-05T14:07:43.649803Z","shell.execute_reply":"2024-06-05T14:07:43.912037Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Save the TensorFlow model\ntf_model.save('resnet50_tf.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:43.914008Z","iopub.execute_input":"2024-06-05T14:07:43.914328Z","iopub.status.idle":"2024-06-05T14:07:44.370523Z","shell.execute_reply.started":"2024-06-05T14:07:43.914301Z","shell.execute_reply":"2024-06-05T14:07:44.369463Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Load the saved TensorFlow model\nloaded_tf_model = tf.keras.models.load_model('resnet50_tf.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:44.371950Z","iopub.execute_input":"2024-06-05T14:07:44.372290Z","iopub.status.idle":"2024-06-05T14:07:45.297053Z","shell.execute_reply.started":"2024-06-05T14:07:44.372262Z","shell.execute_reply":"2024-06-05T14:07:45.296010Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"n_parameters = loaded_tf_model.count_params()\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T14:07:45.298650Z","iopub.execute_input":"2024-06-05T14:07:45.298952Z","iopub.status.idle":"2024-06-05T14:07:45.305621Z","shell.execute_reply.started":"2024-06-05T14:07:45.298927Z","shell.execute_reply":"2024-06-05T14:07:45.304573Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Number of Params: 25.6M\n","output_type":"stream"}]}]}