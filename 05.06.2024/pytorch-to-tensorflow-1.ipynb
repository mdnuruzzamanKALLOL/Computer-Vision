{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":58130,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":48728}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Pytorch**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n#from torchsummary import summary\n\nclass custom_pytorch(nn.Module):\n    def __init__(self, num_classes):\n        super(custom_pytorch, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(256 * 14 * 14, 1024)\n        self.fc2 = nn.Linear(1024, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n        x = x.view(-1, 256 * 14 * 14)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n    \n# Create an instance of the model\nnum_classes = 10\nmodel = custom_pytorch(num_classes)\n#model.load_state_dict(torch.load('/kaggle/working/custom.pth'))\n\nn_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:27.681662Z","iopub.execute_input":"2024-06-04T12:28:27.682066Z","iopub.status.idle":"2024-06-04T12:28:31.535620Z","shell.execute_reply.started":"2024-06-04T12:28:27.682033Z","shell.execute_reply":"2024-06-04T12:28:31.534698Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Number of Params: 51.8M\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'custom.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:31.537547Z","iopub.execute_input":"2024-06-04T12:28:31.538100Z","iopub.status.idle":"2024-06-04T12:28:31.762499Z","shell.execute_reply.started":"2024-06-04T12:28:31.538064Z","shell.execute_reply":"2024-06-04T12:28:31.761706Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Tensorflow**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef custom_tensorflow(num_classes):\n    inputs = tf.keras.Input(shape=(224, 224, 3))\n    \n    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)  # Layer 1\n    x = layers.BatchNormalization()(x)  # Layer 2\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 3\n    \n    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)  # Layer 4\n    x = layers.BatchNormalization()(x)  # Layer 5\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 6\n    \n    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)  # Layer 7\n    x = layers.BatchNormalization()(x)  # Layer 8\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 9\n    \n    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)  # Layer 10\n    x = layers.BatchNormalization()(x)  # Layer 11\n    x = layers.MaxPooling2D((2, 2))(x)  # Layer 12\n    \n    x = layers.Flatten()(x)  # Layer 13\n    x = layers.Dropout(0.5)(x)  # Layer 14\n    x = layers.Dense(1024, activation='relu')(x)  # Layer 15\n    x = layers.Dropout(0.5)(x)  # Layer 16\n    outputs = layers.Dense(num_classes, activation='softmax')(x)  # Layer 17\n    \n    model = models.Model(inputs, outputs)\n    return model\n\n# Create an instance of the model\nnum_classes = 10\ntf_model = custom_tensorflow(num_classes)\n\nn_parameters = tf_model.count_params()\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:31.763523Z","iopub.execute_input":"2024-06-04T12:28:31.763807Z","iopub.status.idle":"2024-06-04T12:28:45.059630Z","shell.execute_reply.started":"2024-06-04T12:28:31.763781Z","shell.execute_reply":"2024-06-04T12:28:45.058631Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-04 12:28:33.650886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-04 12:28:33.650987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-04 12:28:33.780530: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Number of Params: 51.8M\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Translate weight**","metadata":{}},{"cell_type":"code","source":"pytorch_model = custom_pytorch(num_classes)\n\npytorch_model.load_state_dict(torch.load('/kaggle/working/custom.pth', map_location=torch.device('cpu')))\npytorch_model.eval()\n\n# Helper function to convert PyTorch tensors to NumPy arrays\ndef pt_to_np(tensor):\n    return tensor.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:45.061544Z","iopub.execute_input":"2024-06-04T12:28:45.062089Z","iopub.status.idle":"2024-06-04T12:28:45.707786Z","shell.execute_reply.started":"2024-06-04T12:28:45.062061Z","shell.execute_reply":"2024-06-04T12:28:45.706955Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Map PyTorch weights to TensorFlow model\ntf_model.layers[1].set_weights([pt_to_np(pytorch_model.conv1.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv1.bias)])\ntf_model.layers[2].set_weights([pt_to_np(pytorch_model.bn1.weight), pt_to_np(pytorch_model.bn1.bias),\n                                pt_to_np(pytorch_model.bn1.running_mean), pt_to_np(pytorch_model.bn1.running_var)])\n\ntf_model.layers[4].set_weights([pt_to_np(pytorch_model.conv2.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv2.bias)])\ntf_model.layers[5].set_weights([pt_to_np(pytorch_model.bn2.weight), pt_to_np(pytorch_model.bn2.bias),\n                                pt_to_np(pytorch_model.bn2.running_mean), pt_to_np(pytorch_model.bn2.running_var)])\n\ntf_model.layers[7].set_weights([pt_to_np(pytorch_model.conv3.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv3.bias)])\ntf_model.layers[8].set_weights([pt_to_np(pytorch_model.bn3.weight), pt_to_np(pytorch_model.bn3.bias),\n                                pt_to_np(pytorch_model.bn3.running_mean), pt_to_np(pytorch_model.bn3.running_var)])\n\ntf_model.layers[10].set_weights([pt_to_np(pytorch_model.conv4.weight.permute(2, 3, 1, 0)), pt_to_np(pytorch_model.conv4.bias)])\ntf_model.layers[11].set_weights([pt_to_np(pytorch_model.bn4.weight), pt_to_np(pytorch_model.bn4.bias),\n                                 pt_to_np(pytorch_model.bn4.running_mean), pt_to_np(pytorch_model.bn4.running_var)])\n\ntf_model.layers[15].set_weights([pt_to_np(pytorch_model.fc1.weight.T), pt_to_np(pytorch_model.fc1.bias)])\ntf_model.layers[17].set_weights([pt_to_np(pytorch_model.fc2.weight.T), pt_to_np(pytorch_model.fc2.bias)])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:45.708875Z","iopub.execute_input":"2024-06-04T12:28:45.709166Z","iopub.status.idle":"2024-06-04T12:28:46.275969Z","shell.execute_reply.started":"2024-06-04T12:28:45.709140Z","shell.execute_reply":"2024-06-04T12:28:46.274959Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tf_model.save('custom.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:46.277117Z","iopub.execute_input":"2024-06-04T12:28:46.277386Z","iopub.status.idle":"2024-06-04T12:28:46.721462Z","shell.execute_reply.started":"2024-06-04T12:28:46.277363Z","shell.execute_reply":"2024-06-04T12:28:46.720664Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"load_tf_model = models.load_model('/kaggle/working/custom.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:46.722626Z","iopub.execute_input":"2024-06-04T12:28:46.723036Z","iopub.status.idle":"2024-06-04T12:28:47.234475Z","shell.execute_reply.started":"2024-06-04T12:28:46.723007Z","shell.execute_reply":"2024-06-04T12:28:47.233722Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"n_parameters = load_tf_model.count_params()\nprint(f\"Number of Params: {n_parameters / 1000000:.1f}M\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:28:47.235516Z","iopub.execute_input":"2024-06-04T12:28:47.235805Z","iopub.status.idle":"2024-06-04T12:28:47.240736Z","shell.execute_reply.started":"2024-06-04T12:28:47.235780Z","shell.execute_reply":"2024-06-04T12:28:47.239829Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of Params: 51.8M\n","output_type":"stream"}]}]}